{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cycle_GAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data as data\n",
        "import random\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os , itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "tWAkxz_JYMSG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'batch_size':10,\n",
        "    'input_size':256,\n",
        "    'resize_scale':286,\n",
        "    'crop_size':256,\n",
        "    'fliplr':True,\n",
        "    #model params\n",
        "    'num_epochs':25,\n",
        "    'decay_epoch':100,\n",
        "    'ngf':32,   #number of generator filters\n",
        "    'ndf':64,   #number of discriminator filters\n",
        "    'num_resnet':6, #number of resnet blocks\n",
        "    'lrG':0.0002,    #learning rate for generator\n",
        "    'lrD':0.0002,    #learning rate for discriminator\n",
        "    'beta1':0.5 ,    #beta1 for Adam optimizer\n",
        "    'beta2':0.999 ,  #beta2 for Adam optimizer\n",
        "    'lambdaA':10 ,   #lambdaA for cycle loss\n",
        "    'lambdaB':10  ,  #lambdaB for cycle loss\n",
        "}"
      ],
      "metadata": {
        "id": "K6ruILXfZBy9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyPI3XcquFCo",
        "outputId": "73bb5ad2-5a71-472c-f84f-cb668ad09c7c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/MyDrive/selfie2anime/'\n",
        "def to_np(x):\n",
        "    return x.data.cpu().numpy()\n",
        "def plot_train_result(real_image, gen_image, recon_image, epoch, save=False,  show=True, fig_size=(15, 15)):\n",
        "    fig, axes = plt.subplots(2, 3, figsize=fig_size)\n",
        "    imgs = [to_np(real_image[0]), to_np(gen_image[0]), to_np(recon_image[0]),\n",
        "            to_np(real_image[1]), to_np(gen_image[1]), to_np(recon_image[1])]\n",
        "    for ax, img in zip(axes.flatten(), imgs):\n",
        "        ax.axis('off')\n",
        "        #ax.set_adjustable('box-forced')\n",
        "        # Scale to 0-255\n",
        "        img = img.squeeze()\n",
        "        img = (((img - img.min()) * 255) / (img.max() - img.min())).transpose(1, 2, 0).astype(np.uint8)\n",
        "        ax.imshow(img, cmap=None, aspect='equal')\n",
        "    plt.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "    title = 'Epoch {0}'.format(epoch + 1)\n",
        "    fig.text(0.5, 0.04, title, ha='center')\n",
        "\n",
        "    # save figure\n",
        "    if save:\n",
        "        save_fn = 'Result_epoch_{:d}'.format(epoch+1) + '.png'\n",
        "        plt.savefig(save_fn)\n",
        "\n",
        "    if show:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.close()"
      ],
      "metadata": {
        "id": "r16SGFyQZG3N"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "90fH3wI3hP6g"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImagePool():\n",
        "    def __init__(self, pool_size):\n",
        "        self.pool_size = pool_size\n",
        "        if self.pool_size > 0:\n",
        "            self.num_imgs = 0\n",
        "            self.images = []\n",
        "\n",
        "    def query(self, images):\n",
        "        if self.pool_size == 0:\n",
        "            return images\n",
        "        return_images = []\n",
        "        for image in images.data:\n",
        "            image = torch.unsqueeze(image, 0)\n",
        "            if self.num_imgs < self.pool_size:\n",
        "                self.num_imgs = self.num_imgs + 1\n",
        "                self.images.append(image)\n",
        "                return_images.append(image)\n",
        "            else:\n",
        "                p = random.uniform(0, 1)\n",
        "                if p > 0.5:\n",
        "                    random_id = random.randint(0, self.pool_size-1)\n",
        "                    tmp = self.images[random_id].clone()\n",
        "                    self.images[random_id] = image\n",
        "                    return_images.append(tmp)\n",
        "                else:\n",
        "                    return_images.append(image)\n",
        "        return_images = Variable(torch.cat(return_images, 0))\n",
        "        return return_images"
      ],
      "metadata": {
        "id": "CNEcfaOCZM0F"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DatasetFromFolder(data.Dataset):\n",
        "    def __init__(self, image_dir, subfolder='test', transform=None, resize_scale=None, crop_size=None, fliplr=False):\n",
        "        super(DatasetFromFolder, self).__init__()\n",
        "        self.input_path = os.path.join(image_dir, subfolder)\n",
        "        self.image_filenames = [x for x in sorted(os.listdir(self.input_path))]\n",
        "        self.transform = transform\n",
        "        \n",
        "        self.resize_scale = resize_scale\n",
        "        self.crop_size = crop_size\n",
        "        self.fliplr = fliplr\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Load Image\n",
        "        img_fn = os.path.join(self.input_path, self.image_filenames[index])\n",
        "        img = Image.open(img_fn).convert('RGB')\n",
        "\n",
        "        # preprocessing\n",
        "        if self.resize_scale:\n",
        "            img = img.resize((self.resize_scale, self.resize_scale), Image.BILINEAR)\n",
        "\n",
        "        if self.crop_size:\n",
        "            x = random.randint(0, self.resize_scale - self.crop_size + 1)\n",
        "            y = random.randint(0, self.resize_scale - self.crop_size + 1)\n",
        "            img = img.crop((x, y, x + self.crop_size, y + self.crop_size))\n",
        "        if self.fliplr:\n",
        "            if random.random() < 0.5:\n",
        "                img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)"
      ],
      "metadata": {
        "id": "pOCdI-edZPXd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(torch.nn.Module):\n",
        "    def __init__(self,input_size,output_size,kernel_size=3,stride=2,padding=1,activation='relu',batch_norm=True):\n",
        "        super(ConvBlock,self).__init__()\n",
        "        self.conv = torch.nn.Conv2d(input_size,output_size,kernel_size,stride,padding)\n",
        "        self.batch_norm = batch_norm\n",
        "        self.bn = torch.nn.InstanceNorm2d(output_size)\n",
        "        self.activation = activation\n",
        "        self.relu = torch.nn.ReLU(True)\n",
        "        self.lrelu = torch.nn.LeakyReLU(0.2,True)\n",
        "        self.tanh = torch.nn.Tanh()\n",
        "    def forward(self,x):\n",
        "        if self.batch_norm:\n",
        "            out = self.bn(self.conv(x))\n",
        "        else:\n",
        "            out = self.conv(x)\n",
        "        \n",
        "        if self.activation == 'relu':\n",
        "            return self.relu(out)\n",
        "        elif self.activation == 'lrelu':\n",
        "            return self.lrelu(out)\n",
        "        elif self.activation == 'tanh':\n",
        "            return self.tanh(out)\n",
        "        elif self.activation == 'no_act':\n",
        "            return out"
      ],
      "metadata": {
        "id": "b2MYAmA9ZR2M"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DeconvBlock(torch.nn.Module):\n",
        "    def __init__(self,input_size,output_size,kernel_size=3,stride=2,padding=1,output_padding=1,activation='relu',batch_norm=True):\n",
        "        super(DeconvBlock,self).__init__()\n",
        "        self.deconv = torch.nn.ConvTranspose2d(input_size,output_size,kernel_size,stride,padding,output_padding)\n",
        "        self.batch_norm = batch_norm\n",
        "        self.bn = torch.nn.InstanceNorm2d(output_size)\n",
        "        self.activation = activation\n",
        "        self.relu = torch.nn.ReLU(True)\n",
        "    def forward(self,x):\n",
        "        if self.batch_norm:\n",
        "            out = self.bn(self.deconv(x))\n",
        "        else:\n",
        "            out = self.deconv(x)\n",
        "        if self.activation == 'relu':\n",
        "            return self.relu(out)\n",
        "        elif self.activation == 'lrelu':\n",
        "            return self.lrelu(out)\n",
        "        elif self.activation == 'tanh':\n",
        "            return self.tanh(out)\n",
        "        elif self.activation == 'no_act':\n",
        "            return out"
      ],
      "metadata": {
        "id": "1l1YRQfBZUCU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResnetBlock(torch.nn.Module):\n",
        "    def __init__(self,num_filter,kernel_size=3,stride=1,padding=0):\n",
        "        super(ResnetBlock,self).__init__()\n",
        "        conv1 = torch.nn.Conv2d(num_filter,num_filter,kernel_size,stride,padding)\n",
        "        conv2 = torch.nn.Conv2d(num_filter,num_filter,kernel_size,stride,padding)\n",
        "        bn = torch.nn.InstanceNorm2d(num_filter)\n",
        "        relu = torch.nn.ReLU(True)\n",
        "        pad = torch.nn.ReflectionPad2d(1)\n",
        "        \n",
        "        self.resnet_block = torch.nn.Sequential(\n",
        "            pad,\n",
        "            conv1,\n",
        "            bn,\n",
        "            relu,\n",
        "            pad,\n",
        "            conv2,\n",
        "            bn\n",
        "            )\n",
        "    def forward(self,x):\n",
        "        out = self.resnet_block(x)\n",
        "        return out"
      ],
      "metadata": {
        "id": "QKojiAwlZV9l"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(torch.nn.Module):\n",
        "    def __init__(self,input_dim,num_filter,output_dim,num_resnet):\n",
        "        super(Generator,self).__init__()\n",
        "        \n",
        "        #Reflection padding\n",
        "        self.pad = torch.nn.ReflectionPad2d(3)\n",
        "        #Encoder\n",
        "        self.conv1 = ConvBlock(input_dim,num_filter,kernel_size=7,stride=1,padding=0)\n",
        "        self.conv2 = ConvBlock(num_filter,num_filter*2)\n",
        "        self.conv3 = ConvBlock(num_filter*2,num_filter*4)\n",
        "        #Resnet blocks\n",
        "        self.resnet_blocks = []\n",
        "        for i in range(num_resnet):\n",
        "            self.resnet_blocks.append(ResnetBlock(num_filter*4))\n",
        "        self.resnet_blocks = torch.nn.Sequential(*self.resnet_blocks)\n",
        "        #Decoder\n",
        "        self.deconv1 = DeconvBlock(num_filter*4,num_filter*2)\n",
        "        self.deconv2 = DeconvBlock(num_filter*2,num_filter)\n",
        "        self.deconv3 = ConvBlock(num_filter,output_dim,kernel_size=7,stride=1,padding=0,activation='tanh',batch_norm=False)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        #Encoder\n",
        "        enc1 = self.conv1(self.pad(x))\n",
        "        enc2 = self.conv2(enc1)\n",
        "        enc3 = self.conv3(enc2)\n",
        "        #Resnet blocks\n",
        "        res = self.resnet_blocks(enc3)\n",
        "        #Decoder\n",
        "        dec1 = self.deconv1(res)\n",
        "        dec2 = self.deconv2(dec1)\n",
        "        out = self.deconv3(self.pad(dec2))\n",
        "        return out\n",
        "    \n",
        "    def normal_weight_init(self,mean=0.0,std=0.02):\n",
        "        for m in self.children():\n",
        "            if isinstance(m,ConvBlock):\n",
        "                torch.nn.init.normal_(m.conv.weight,mean,std)\n",
        "            if isinstance(m,DeconvBlock):\n",
        "                torch.nn.init.normal_(m.deconv.weight,mean,std)\n",
        "            if isinstance(m,ResnetBlock):\n",
        "                torch.nn.init.normal_(m.conv.weight,mean,std)\n",
        "                torch.nn.init.constant_(m.conv.bias,0)"
      ],
      "metadata": {
        "id": "prwVhWXoZXyM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(torch.nn.Module):\n",
        "    def __init__(self,input_dim,num_filter,output_dim):\n",
        "        super(Discriminator,self).__init__()\n",
        "        conv1 = ConvBlock(input_dim,num_filter,kernel_size=4,stride=2,padding=1,activation='lrelu',batch_norm=False)\n",
        "        conv2 = ConvBlock(num_filter,num_filter*2,kernel_size=4,stride=2,padding=1,activation='lrelu')\n",
        "        conv3 = ConvBlock(num_filter*2,num_filter*4,kernel_size=4,stride=2,padding=1,activation='lrelu')\n",
        "        conv4 = ConvBlock(num_filter*4,num_filter*8,kernel_size=4,stride=1,padding=1,activation='lrelu')\n",
        "        conv5 = ConvBlock(num_filter*8,output_dim,kernel_size=4,stride=1,padding=1,activation='no_act',batch_norm=False)\n",
        "        self.conv_blocks = torch.nn.Sequential(\n",
        "            conv1,\n",
        "            conv2,\n",
        "            conv3,\n",
        "            conv4,\n",
        "            conv5\n",
        "            )\n",
        "    def forward(self,x):\n",
        "        out = self.conv_blocks(x)\n",
        "        return out\n",
        "        \n",
        "    def normal_weight_init(self,mean=0.0,std=0.02):\n",
        "        for m in self.children():\n",
        "            if isinstance(m,ConvBlock):\n",
        "                torch.nn.init.normal_(m.conv.weight.data,mean,std)"
      ],
      "metadata": {
        "id": "s_XmIdvtZdrt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(size=params['input_size']),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "])\n",
        "train_data_A = DatasetFromFolder(data_dir, subfolder='testA', transform=transform,\n",
        "                                resize_scale=params['resize_scale'], crop_size=params['crop_size'], fliplr=params['fliplr'])\n",
        "train_data_loader_A = torch.utils.data.DataLoader(dataset=train_data_A, batch_size=params['batch_size'], shuffle=True)\n",
        "train_data_B = DatasetFromFolder(data_dir, subfolder='testB', transform=transform,\n",
        "                                resize_scale=params['resize_scale'], crop_size=params['crop_size'], fliplr=params['fliplr'])\n",
        "train_data_loader_B = torch.utils.data.DataLoader(dataset=train_data_B, batch_size=params['batch_size'], shuffle=True)\n",
        "#Load test data\n",
        "test_data_A = DatasetFromFolder(data_dir, subfolder='trainA', transform=transform)\n",
        "test_data_loader_A = torch.utils.data.DataLoader(dataset=test_data_A, batch_size=params['batch_size'], shuffle=False)\n",
        "test_data_B = DatasetFromFolder(data_dir, subfolder='trainB', transform=transform)\n",
        "test_data_loader_B = torch.utils.data.DataLoader(dataset=test_data_B, batch_size=params['batch_size'], shuffle=False)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "E6YlOj2FZeCd"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_real_A_data = train_data_A.__getitem__(11).unsqueeze(0) # Convert to 4d tensor (BxNxHxW)\n",
        "test_real_B_data = train_data_B.__getitem__(91).unsqueeze(0)\n",
        "#print(test_real_A_data)\n",
        "#Build Model \n",
        "G_A = Generator(3, params['ngf'], 3, params['num_resnet']).cuda() # input_dim, num_filter, output_dim, num_resnet\n",
        "G_B = Generator(3, params['ngf'], 3, params['num_resnet']).cuda()\n",
        "\n",
        "D_A = Discriminator(3, params['ndf'], 1).cuda() # input_dim, num_filter, output_dim\n",
        "D_B = Discriminator(3, params['ndf'], 1).cuda()\n",
        "\n",
        "G_A.normal_weight_init(mean=0.0, std=0.02)\n",
        "G_B.normal_weight_init(mean=0.0, std=0.02)\n",
        "D_A.normal_weight_init(mean=0.0, std=0.02)\n",
        "D_B.normal_weight_init(mean=0.0, std=0.02)\n",
        "\n",
        "\n",
        "G_optimizer = torch.optim.Adam(itertools.chain(G_A.parameters(), G_B.parameters()), lr=params['lrG'], betas=(params['beta1'], params['beta2']))\n",
        "D_A_optimizer = torch.optim.Adam(D_A.parameters(), lr=params['lrD'], betas=(params['beta1'], params['beta2']))\n",
        "D_B_optimizer = torch.optim.Adam(D_B.parameters(), lr=params['lrD'], betas=(params['beta1'], params['beta2']))\n",
        "\n",
        "MSE_Loss = torch.nn.MSELoss().cuda()\n",
        "L1_Loss = torch.nn.L1Loss().cuda()\n",
        "\n",
        "# # Training GAN\n",
        "D_A_avg_losses = []\n",
        "D_B_avg_losses = []\n",
        "G_A_avg_losses = []\n",
        "G_B_avg_losses = []\n",
        "cycle_A_avg_losses = []\n",
        "cycle_B_avg_losses = []\n",
        "\n",
        "# Generated image pool\n",
        "num_pool = 50\n",
        "fake_A_pool = ImagePool(num_pool)\n",
        "fake_B_pool = ImagePool(num_pool)\n",
        "\n",
        "step = 0"
      ],
      "metadata": {
        "id": "dKjtg3OfZgxc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "f0b8db6a-af26-4e74-f631-78c5bfb2a367"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-4e57cecc1b8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#print(test_real_A_data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Build Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mG_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ngf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_resnet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# input_dim, num_filter, output_dim, num_resnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mG_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ngf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_resnet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \"\"\"\n\u001b[0;32m--> 680\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \"\"\"\n\u001b[0;32m--> 680\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(params['num_epochs']):\n",
        "    D_A_losses = []\n",
        "    D_B_losses = []\n",
        "    G_A_losses = []\n",
        "    G_B_losses = []\n",
        "    cycle_A_losses = []\n",
        "    cycle_B_losses = []\n",
        "    \n",
        "    # Learing rate decay \n",
        "    if(epoch + 1) > params['decay_epoch']:\n",
        "        D_A_optimizer.param_groups[0]['lr'] -= params['lrD'] / (params['num_epochs'] - params['decay_epoch'])\n",
        "        D_B_optimizer.param_groups[0]['lr'] -= params['lrD'] / (params['num_epochs'] - params['decay_epoch'])\n",
        "        G_optimizer.param_groups[0]['lr'] -= params['lrG'] / (params['num_epochs'] - params['decay_epoch'])\n",
        "        \n",
        "    \n",
        "    # training \n",
        "    for i, (real_A, real_B) in enumerate(zip(train_data_loader_A, train_data_loader_B)):\n",
        "        \n",
        "        # input image data\n",
        "        real_A = real_A.to(device)\n",
        "        real_B = real_B.to(device)\n",
        "        \n",
        "        # -------------------------- train generator G --------------------------\n",
        "        # A --> B\n",
        "        fake_B = G_A(real_A)\n",
        "        D_B_fake_decision = D_B(fake_B)\n",
        "        G_A_loss = MSE_Loss(D_B_fake_decision, Variable(torch.ones(D_B_fake_decision.size()).cuda()))\n",
        "        \n",
        "        # forward cycle loss\n",
        "        recon_A = G_B(fake_B)\n",
        "        cycle_A_loss = L1_Loss(recon_A, real_A) * params['lambdaA']\n",
        "        \n",
        "        # B --> A\n",
        "        fake_A = G_B(real_B)\n",
        "        D_A_fake_decision = D_A(fake_A)\n",
        "        G_B_loss = MSE_Loss(D_A_fake_decision, Variable(torch.ones(D_A_fake_decision.size()).cuda()))\n",
        "        \n",
        "        # backward cycle loss\n",
        "        recon_B = G_A(fake_A)\n",
        "        cycle_B_loss = L1_Loss(recon_B, real_B) * params['lambdaB']\n",
        "        \n",
        "        # Back propagation\n",
        "        G_loss = G_A_loss + G_B_loss + cycle_A_loss + cycle_B_loss\n",
        "        G_optimizer.zero_grad()\n",
        "        G_loss.backward()\n",
        "        G_optimizer.step()\n",
        "        \n",
        "        \n",
        "        # -------------------------- train discriminator D_A --------------------------\n",
        "        D_A_real_decision = D_A(real_A)\n",
        "        D_A_real_loss = MSE_Loss(D_A_real_decision, Variable(torch.ones(D_A_real_decision.size()).cuda()))\n",
        "        \n",
        "        fake_A = fake_A_pool.query(fake_A)\n",
        "        \n",
        "        D_A_fake_decision = D_A(fake_A)\n",
        "        D_A_fake_loss = MSE_Loss(D_A_fake_decision, Variable(torch.zeros(D_A_fake_decision.size()).cuda()))\n",
        "        \n",
        "        # Back propagation\n",
        "        D_A_loss = (D_A_real_loss + D_A_fake_loss) * 0.5\n",
        "        D_A_optimizer.zero_grad()\n",
        "        D_A_loss.backward()\n",
        "        D_A_optimizer.step()\n",
        "        \n",
        "        # -------------------------- train discriminator D_B --------------------------\n",
        "        D_B_real_decision = D_B(real_B)\n",
        "        D_B_real_loss = MSE_Loss(D_B_real_decision, Variable(torch.ones(D_B_fake_decision.size()).cuda()))\n",
        "        \n",
        "        fake_B = fake_B_pool.query(fake_B)\n",
        "        \n",
        "        D_B_fake_decision = D_B(fake_B)\n",
        "        D_B_fake_loss = MSE_Loss(D_B_fake_decision, Variable(torch.zeros(D_B_fake_decision.size()).cuda()))\n",
        "        \n",
        "        # Back propagation\n",
        "        D_B_loss = (D_B_real_loss + D_B_fake_loss) * 0.5\n",
        "        D_B_optimizer.zero_grad()\n",
        "        D_B_loss.backward()\n",
        "        D_B_optimizer.step()\n",
        "        \n",
        "        # ------------------------ Print -----------------------------\n",
        "        # loss values\n",
        "        D_A_losses.append(D_A_loss.item())\n",
        "        D_B_losses.append(D_B_loss.item())\n",
        "        G_A_losses.append(G_A_loss.item())\n",
        "        G_B_losses.append(G_B_loss.item())\n",
        "        cycle_A_losses.append(cycle_A_loss.item())\n",
        "        cycle_B_losses.append(cycle_B_loss.item())\n",
        "\n",
        "        if i%100 == 0:\n",
        "            print('Epoch [%d/%d], Step [%d/%d], D_A_loss: %.4f, D_B_loss: %.4f, G_A_loss: %.4f, G_B_loss: %.4f'\n",
        "                  % (epoch+1, params['num_epochs'], i+1, len(train_data_loader_A), D_A_loss.item(), D_B_loss.item(), G_A_loss.item(), G_B_loss.item()))\n",
        "            \n",
        "        step += 1\n",
        "        \n",
        "    D_A_avg_loss = torch.mean(torch.FloatTensor(D_A_losses))\n",
        "    D_B_avg_loss = torch.mean(torch.FloatTensor(D_B_losses))\n",
        "    G_A_avg_loss = torch.mean(torch.FloatTensor(G_A_losses))\n",
        "    G_B_avg_loss = torch.mean(torch.FloatTensor(G_B_losses))\n",
        "    cycle_A_avg_loss = torch.mean(torch.FloatTensor(cycle_A_losses))\n",
        "    cycle_B_avg_loss = torch.mean(torch.FloatTensor(cycle_B_losses))\n",
        "\n",
        "    # avg loss values for plot\n",
        "    D_A_avg_losses.append(D_A_avg_loss.item())\n",
        "    D_B_avg_losses.append(D_B_avg_loss.item())\n",
        "    G_A_avg_losses.append(G_A_avg_loss.item())\n",
        "    G_B_avg_losses.append(G_B_avg_loss.item())\n",
        "    cycle_A_avg_losses.append(cycle_A_avg_loss.item())\n",
        "    cycle_B_avg_losses.append(cycle_B_avg_loss.item())\n",
        "    \n",
        "    # Show result for test image\n",
        "    test_real_A = test_real_A_data.cuda()\n",
        "    test_fake_B = G_A(test_real_A)\n",
        "    test_recon_A = G_B(test_fake_B)\n",
        "\n",
        "    test_real_B = test_real_B_data.cuda()\n",
        "    test_fake_A = G_B(test_real_B)\n",
        "    test_recon_B = G_A(test_fake_A)\n",
        "\n",
        "    plot_train_result([test_real_A, test_real_B], [test_fake_B, test_fake_A], [test_recon_A, test_recon_B],\n",
        "                            epoch, save=True)"
      ],
      "metadata": {
        "id": "kV2cPPTfZky8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example of calculating the frechet inception distance\n",
        "import numpy\n",
        "from numpy import cov\n",
        "from numpy import trace\n",
        "from numpy import iscomplexobj\n",
        "from numpy.random import random\n",
        "from scipy.linalg import sqrtm\n",
        "\n",
        "# calculate frechet inception distance\n",
        "def calculate_fid(act1, act2):\n",
        "\t# calculate mean and covariance statistics\n",
        "\tmu1, sigma1 = act1.mean(axis=0), cov(act1, rowvar=False)\n",
        "\tmu2, sigma2 = act2.mean(axis=0), cov(act2, rowvar=False)\n",
        "\t# calculate sum squared difference between means\n",
        "\tssdiff = numpy.sum((mu1 - mu2)**2.0)\n",
        "\t# calculate sqrt of product between cov\n",
        "\tcovmean = sqrtm(sigma1.dot(sigma2))\n",
        "\t# check and correct imaginary numbers from sqrt\n",
        "\tif iscomplexobj(covmean):\n",
        "\t\tcovmean = covmean.real\n",
        "\t# calculate score\n",
        "\tfid = ssdiff + trace(sigma1 + sigma2 - 2.0 * covmean)\n",
        "\treturn fid\n",
        "\n",
        "# define two collections of activations\n",
        "act1 = random(10*2048)\n",
        "act1 = act1.reshape((10,2048))\n",
        "act2 = random(10*2048)\n",
        "act2 = act2.reshape((10,2048))\n",
        "# fid between act1 and act1\n",
        "fid = calculate_fid(act1, act1)\n",
        "print('FID (same): %.3f' % fid)\n",
        "# fid between act1 and act2\n",
        "fid = calculate_fid(act1, act2)\n",
        "print('FID (different): %.3f' % fid)"
      ],
      "metadata": {
        "id": "DSNnbZSdZ96l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}